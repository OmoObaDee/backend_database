{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6fd4109",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Required Libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import math\n",
    "from typing import Tuple, List, Optional, Dict\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score, roc_auc_score\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "58c19425",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # loading of dataset\n",
    "# source=\"https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/EasyVisa%20(1).csv\"\n",
    "# data_path = pd.read_csv(source)\n",
    "# data_path.head()\n",
    "# print(f\"Data loaded successfully! Shape: {data_path.shape}\")\n",
    "# # # -------------------------------\n",
    "# # def load_dataset(path_or_url):\n",
    "# #     \"\"\"Load dataset from a local path or URL.\"\"\"\n",
    "# #     df = pd.read_csv(path_or_url)\n",
    "# #     print(f\"Data loaded successfully! Shape: {df.shape}\")\n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "365800f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path=\"https://raw.githubusercontent.com/ek-chris/Practice_datasets/refs/heads/main/EasyVisa%20(1).csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea6cbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python3# Import Required Libraries\n",
    "# Import Required Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "\n",
    "def perform_eda(data_path, output_dir=\"eda_results\"):\n",
    "    \"\"\"\n",
    "    Performs full EDA on dataset and saves all outputs.\n",
    "    -------------------------------------------------------\n",
    "    Parameters:\n",
    "        data_path (str): Path or URL to the dataset.\n",
    "        output_dir (str): Folder to save results.\n",
    "    -------------------------------------------------------\n",
    "    Returns:\n",
    "        df (pd.DataFrame): Cleaned dataset ready for modeling.\n",
    "    -------------------------------------------------------\n",
    "    \"\"\"\n",
    "\n",
    "    #================================\n",
    "    # 1. Create Output Folder\n",
    "    #================================\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    print(f\"Results will be saved to: {output_dir}\")\n",
    "\n",
    "    #================================\n",
    "    # 2. Load Dataset\n",
    "    #================================\n",
    "    df = pd.read_csv(data_path)\n",
    "    print(f\" Data Loaded — Shape: {df.shape}\\n\")\n",
    "\n",
    "    #================================\n",
    "    # 3. Save Basic Info\n",
    "    #================================\n",
    "    # ---------------------------\n",
    "    with open(os.path.join(output_dir, \"data_summary.txt\"), \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(\"=== DATA SUMMARY REPORT ===\\n\\n\")\n",
    "        f.write(f\"Dataset Shape: {df.shape}\\n\\n\")\n",
    "        f.write(\"DATA TYPES:\\n\")\n",
    "        f.write(str(df.dtypes))\n",
    "        f.write(\"\\n\\nMISSING VALUES:\\n\")\n",
    "        f.write(str(df.isnull().sum()))\n",
    "        f.write(\"\\n\\nDESCRIPTIVE STATS:\\n\")\n",
    "        f.write(str(df.describe(include='all')))\n",
    "        f.write(\"\\n\\nDUPLICATES:\\n\")\n",
    "        f.write(str(df.duplicated().sum()))\n",
    "    print(\"Data summary saved as 'data_summary.txt'\")\n",
    "\n",
    "    # ==================================\n",
    "    # 4. Missing Values Heatmap\n",
    "    # ==================================\n",
    "    plt.figure(figsize=(10, 5))\n",
    "    sns.heatmap(df.isnull(), cbar=False, cmap=\"coolwarm\")\n",
    "    plt.title(\"Missing Values Heatmap\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(output_dir, \"missing_values_heatmap.png\"))\n",
    "    plt.close()\n",
    "\n",
    "    # ==================================\n",
    "    # 5. Remove Duplicates\n",
    "    # ==================================\n",
    "    dup_count = df.duplicated().sum()\n",
    "    if dup_count > 0:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(f\"Removed {dup_count} duplicate rows.\")\n",
    "\n",
    "    # ==================================\n",
    "    # 6. Identify Numeric & Categorical Columns\n",
    "    # ==================================\n",
    "    num_cols = df.select_dtypes(include=np.number).columns.tolist()\n",
    "    cat_cols = df.select_dtypes(exclude=np.number).columns.tolist()\n",
    "\n",
    "    # ==================================\n",
    "    # 7. Univariate Analysis — Save Plots\n",
    "    # ==================================\n",
    "    for col in num_cols:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        sns.histplot(df[col], kde=True, color=\"royalblue\")\n",
    "        plt.title(f\"Distribution of {col}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"dist_{col}.png\"))\n",
    "        plt.close()\n",
    "        \n",
    "\n",
    "    for col in cat_cols:\n",
    "        plt.figure(figsize=(6, 4))\n",
    "        df[col].value_counts().head(10).plot(kind=\"bar\", color=\"teal\")\n",
    "        plt.title(f\"Top Categories for {col}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"cat_{col}.png\"))\n",
    "        plt.close()\n",
    "\n",
    "    print(f\"Distribution plots saved for {len(num_cols) + len(cat_cols)} columns.\")\n",
    "\n",
    "    # ==================================\n",
    "    # 8. Correlation Heatmap\n",
    "    # ==================================\n",
    "    if len(num_cols) > 1:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        sns.heatmap(df[num_cols].corr(), annot=True, cmap=\"viridis\", fmt=\".2f\")\n",
    "        plt.title(\"Correlation Heatmap\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, \"correlation_heatmap.png\"))\n",
    "        plt.close()\n",
    "        print(\"Correlation heatmap saved.\")\n",
    "\n",
    "    # ==================================\n",
    "    # 9. Outlier Detection Plots\n",
    "    # ==================================\n",
    "    for col in num_cols:\n",
    "        plt.figure(figsize=(6, 3))\n",
    "        sns.boxplot(x=df[col], color=\"coral\")\n",
    "        plt.title(f\"Boxplot for {col}\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(output_dir, f\"boxplot_{col}.png\"))\n",
    "        plt.close()\n",
    "    print(\"Outlier boxplots saved.\")\n",
    "\n",
    "    # ==================================\n",
    "    # 10. Handle Missing Values\n",
    "    # ==================================\n",
    "    for col in num_cols:\n",
    "        df[col].fillna(df[col].median(), inplace=True)\n",
    "\n",
    "    for col in cat_cols:\n",
    "        df[col].fillna(df[col].mode()[0], inplace=True)\n",
    "\n",
    "    print(\"Missing values filled: Median (numeric), Mode (categorical).\")\n",
    "\n",
    "    # ==================================\n",
    "    # 11. Save Cleaned Dataset\n",
    "    # ==================================\n",
    "    cleaned_path = os.path.join(output_dir, \"cleaned_easyvisa.csv\")\n",
    "    df.to_csv(cleaned_path, index=False)\n",
    "    print(f\"Cleaned dataset saved to '{cleaned_path}'\")\n",
    "\n",
    "    print(\"\\nEDA + Cleaning Completed. All summary outputs of EDA saved successfully.\")\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26fc045d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results will be saved to: eda_summary\n",
      " Data Loaded — Shape: (25480, 12)\n",
      "\n",
      "Data summary saved as 'data_summary.txt'\n",
      "Distribution plots saved for 12 columns.\n",
      "Correlation heatmap saved.\n",
      "Outlier boxplots saved.\n",
      "Missing values filled: Median (numeric), Mode (categorical).\n",
      "Cleaned dataset saved to 'eda_summary\\cleaned_easyvisa.csv'\n",
      "\n",
      "EDA + Cleaning Completed. All summary outputs of EDA saved successfully.\n"
     ]
    }
   ],
   "source": [
    "df=perform_eda(data_path,output_dir=\"eda_summary\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Backend",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
